{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7155204,"sourceType":"datasetVersion","datasetId":4132030}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# #16 atmaCup","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## セットアップ","metadata":{}},{"cell_type":"markdown","source":"### ライブラリのインストール","metadata":{}},{"cell_type":"code","source":"# frequency-based regularization版iALSを共役勾配法で解く高速なライブラリ\n# - 公式リポジトリ\n#   - https://github.com/tohtsky/irspack\n# - 開発者による解説記事\n#   - https://engineering.visional.inc/blog/393/ials-revisited/\n!pip install irspack","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ライブラリの読み込み","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy\nfrom sklearn.model_selection import train_test_split\nfrom irspack import (\n    df_to_sparse,\n    IALSRecommender,\n    Evaluator,\n    ItemIDMapper\n)\nfrom tqdm.auto import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"union = lambda x, y: x + y - x.multiply(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### データの読み込み","metadata":{}},{"cell_type":"code","source":"trainvalid_log = pd.read_csv('train_log.csv')\ntrainvalid_label = pd.read_csv('train_label.csv')\ntest_log = pd.read_csv('test_log.csv')\ntest_session = pd.read_csv('test_session.csv')\nyado = pd.read_csv('yado.csv')\nsample_submission = pd.read_csv('sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 前処理","metadata":{}},{"cell_type":"markdown","source":"### セッションと宿の一覧を作成","metadata":{}},{"cell_type":"code","source":"# セッションの一覧\ntrainvalid_user_ids = trainvalid_log['session_id'].drop_duplicates().to_list()\ntest_user_ids = test_log['session_id'].drop_duplicates().to_list()\n\n# 宿の一覧\nitem_ids = yado['yad_no'].drop_duplicates().to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 学習データと検証データに分割\n\n精度検証のため `train_log.csv` を学習データと検証データに分割します。セッションが豊富に存在するため、今回はクロスバリデーションではなくホールドアウトにしました。","metadata":{}},{"cell_type":"code","source":"train_user_ids, valid_user_ids = train_test_split(trainvalid_user_ids, test_size=0.2, random_state=0)\ntrain_log = trainvalid_log.loc[lambda df: df['session_id'].isin(train_user_ids), :].copy()\nvalid_log = trainvalid_log.loc[lambda df: df['session_id'].isin(valid_user_ids), :].copy()\ntrain_label = trainvalid_label.loc[lambda df: df['session_id'].isin(train_user_ids), :].copy()\nvalid_label = trainvalid_label.loc[lambda df: df['session_id'].isin(valid_user_ids), :].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ログを行列へ変換\n\n- 行：セッション (※ `*_user_ids` 順にソートされている)\n- 列：宿 (※ `item_ids` 順にソートされている)\n- 成分：出現 or 予約なら 1、それ以外なら 0","metadata":{}},{"cell_type":"code","source":"def log_to_matrix(log, label, user_ids, item_ids):\n    # 出現した宿\n    matrix_x, _, _ = df_to_sparse(\n        df = log[['session_id', 'yad_no']].drop_duplicates(),\n        user_column='session_id',\n        item_column='yad_no',\n        user_ids=user_ids,\n        item_ids=item_ids\n    )\n\n    # 予約された宿\n    if label is not None:\n        matrix_y, _, _ = df_to_sparse(\n            df=label,\n            user_column='session_id',\n            item_column='yad_no',\n            user_ids=user_ids,\n            item_ids=item_ids\n        )\n    else:\n        matrix_y = None\n\n    # レコメンド対象外の宿 (各セッション内で最後に出現する宿)\n    matrix_mask, _, _ = df_to_sparse(\n        df = (\n            log\n            .merge(\n                log.groupby('session_id')['seq_no'].max().rename('seq_no_max'),\n                how='left',\n                on='session_id'\n            )\n            .loc[lambda df: df['seq_no'] == df['seq_no_max'], :]\n        ),\n        user_column='session_id',\n        item_column='yad_no',\n        user_ids=user_ids,\n        item_ids=item_ids\n    )\n\n    return matrix_x, matrix_y, matrix_mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_matrix_x, train_matrix_y, train_matrix_mask = \\\n    log_to_matrix(train_log, train_label, train_user_ids, item_ids)\nvalid_matrix_x, valid_matrix_y, valid_matrix_mask = \\\n    log_to_matrix(valid_log, valid_label, valid_user_ids, item_ids)\ntest_matrix_x, test_matrix_y, test_matrix_mask = \\\n    log_to_matrix(test_log, None, test_user_ids, item_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ログが2件以上あるセッションのインデックスを抽出\n\nログが1件しかないセッションはノイズになる可能性があるため、学習時に取り除けるよう、該当セッションを取り除いたインデックスをあらかじめ作っておきます。","metadata":{}},{"cell_type":"code","source":"def get_user_ids_seq_no_max_over_1_index(log, user_ids):\n    user_ids_seq_no_max_over_1 = (\n        log\n        .groupby('session_id')['seq_no'].max()\n        .loc[lambda s: s > 0]\n        .index\n        .to_list()\n    )\n    user_ids_seq_no_max_over_1_set = set(user_ids_seq_no_max_over_1)\n    user_ids_seq_no_max_over_1_index = [\n        i\n        for i, user_id in enumerate(user_ids)\n        if user_id in user_ids_seq_no_max_over_1_set\n    ]\n\n    return user_ids_seq_no_max_over_1_index","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_user_ids_seq_no_max_over_1_index = \\\n#     get_user_ids_seq_no_max_over_1_index(train_log, train_user_ids)\n# valid_user_ids_seq_no_max_over_1_index = \\\n#     get_user_ids_seq_no_max_over_1_index(valid_log, valid_user_ids)\ntest_user_ids_seq_no_max_over_1_index = \\\n    get_user_ids_seq_no_max_over_1_index(test_log, test_user_ids)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 学習","metadata":{}},{"cell_type":"markdown","source":"### ハイパラ調整と精度検証","metadata":{}},{"cell_type":"code","source":"valid_evaluator = Evaluator(\n    valid_matrix_y,\n    target_metric='map',\n    cutoff=10,\n    masked_interactions=valid_matrix_mask\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Optunaでハイパラ調整\n# best_params, validation_results_df = IALSRecommender.tune_doubling_dimension(\n#     scipy.sparse.vstack([\n#         valid_matrix_x,\n#         union(train_matrix_x, train_matrix_y)\n#     ]),\n#     valid_evaluator,\n#     initial_dimension=200,\n#     maximal_dimension=1600,\n#     storage='sqlite:///optuna.db',\n#     random_seed=0\n# )\n\n# ハイパラ調整の結果 (メモリ不足で中断したので最適じゃないかも……)\nbest_params = {\n    'n_components': 1600,\n    'alpha0': 0.001297421599991797,\n    'reg': 0.010800184775061342,\n    'train_epochs': 3\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_recommender = IALSRecommender(\n    scipy.sparse.vstack([\n        valid_matrix_x,\n        union(train_matrix_x, train_matrix_y)\n    ]),\n    **best_params,\n    random_seed=0\n).learn()\nvalid_evaluator.get_score(valid_recommender)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 全データ学習","metadata":{}},{"cell_type":"code","source":"test_recommender = IALSRecommender(\n    scipy.sparse.vstack([\n        test_matrix_x,\n        union(train_matrix_x, train_matrix_y),\n        union(valid_matrix_x, valid_matrix_y),\n        # 学習データ-テストデータ間のシフト対策として、テストデータを10倍にする。\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :],\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :],\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :],\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :],\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :],\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :],\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :],\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :],\n        test_matrix_x[test_user_ids_seq_no_max_over_1_index, :]\n    ]),\n    **best_params,\n    random_seed=0\n).learn()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 予測","metadata":{}},{"cell_type":"code","source":"def get_candidates(recommender, offset, matrix_mask, user_ids, item_ids, num_candidates):\n    batch_size = 10000\n    id_mapper = ItemIDMapper(item_ids)\n    cantidates = []\n    for begin in tqdm(range(0, len(user_ids), batch_size)):\n        end = min(begin + batch_size, len(user_ids))\n        score = recommender.get_score_block(begin + offset, end + offset)\n        score[matrix_mask[begin:end, :].nonzero()] = -np.inf\n        cantidates += id_mapper.score_to_recommended_items_batch(score, cutoff=num_candidates)\n    cantidates = (\n        pd.DataFrame(\n            [\n                (user_ids[user_ids_index], rank + 1, yad_no, score)\n                for user_ids_index, cantidates_per_user in enumerate(cantidates)\n                for rank, (yad_no, score) in enumerate(cantidates_per_user)\n            ],\n            columns = ['session_id', 'rank', 'yad_no', 'score']\n        )\n    )\n\n    return cantidates","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_cantidates = get_candidates(\n    valid_recommender,\n    0,\n    valid_matrix_mask,\n    valid_user_ids,\n    item_ids,\n    10\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_cantidates = get_candidates(\n    test_recommender,\n    0,\n    test_matrix_mask,\n    test_user_ids,\n    item_ids,\n    10\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 後処理\n\n[「train_logにおいてsessionの最後のseq_noと途中のseq_noの差分を取ったときに奇数番目の宿が選ばれやすい」](https://www.guruguru.science/competitions/22/discussions/b7abc605-9025-4a64-911e-2c760523db09/) で指摘されている通り、本コンペでは宿の出現順序が大きな意味を持っています。一方で、iALSは宿の出現順序を加味できません。そこで、iALSの予測結果に対して宿の出現順序に関するルールを後処理で適用します。","metadata":{}},{"cell_type":"code","source":"# 各セッションのログの最後から2番目の宿をランキング1位に持ってくる。\ndef add_seq_no_reverse_1_yad(cantidates, log):\n    # 各セッションのログの最後から2番目の宿\n    seq_no_reverse_1_yad = (\n        log\n        .merge(\n            log.groupby('session_id')['seq_no'].max().rename('seq_no_max'),\n            how='left',\n            on='session_id'\n        )\n        .merge(\n            log.groupby('session_id')['yad_no'].nunique().rename('yad_no_nunique'),\n            how='left',\n            on='session_id'\n        )\n        .assign(seq_no_reverse = lambda df: df['seq_no_max'] - df['seq_no'])\n        .loc[lambda df: (df['seq_no_reverse'] == 1) & (df['yad_no_nunique'] == 2), :]\n        .assign(rank = -1)\n        .loc[:, ['session_id', 'rank', 'yad_no']]\n    )\n\n    cantidates_seq_no_reverse_1_yad = (\n        pd.concat([seq_no_reverse_1_yad, cantidates], ignore_index=True)\n        .groupby(['session_id', 'yad_no'], as_index=False)['rank'].min()\n        .sort_values(['session_id', 'rank'])\n        .groupby('session_id').head(10)\n        .assign(rank = lambda df: df.groupby('session_id').cumcount() + 1)\n    )\n\n    return cantidates_seq_no_reverse_1_yad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map10(cantidates, label):\n    return (\n        cantidates\n        .merge(label.assign(label = 1), how='left', on=['session_id', 'yad_no'])\n        .assign(label = lambda df: df['label'].mask(df['label'].isna(), 0))\n        .assign(precision = lambda df: 1 / df['rank'] * df['label'])\n        .groupby('session_id').head(10)\n        .groupby('session_id')['precision'].sum().mean()\n    )\n\n# 後処理なし\nprint(map10(valid_cantidates, valid_label))\n# 後処理あり\nprint(map10(add_seq_no_reverse_1_yad(valid_cantidates, valid_log), valid_label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_cantidates = add_seq_no_reverse_1_yad(test_cantidates, test_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 提出","metadata":{}},{"cell_type":"code","source":"submission = test_cantidates.pivot(index='session_id', columns='rank', values='yad_no')\nsubmission = submission[[i + 1 for i in range(10)]].copy()\nsubmission = submission.loc[test_session['session_id'], :].copy()\nsubmission.columns = sample_submission.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(f'submission.csv', index=False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}